{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''Read the data '''\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy \n\ndef data(): \n    # load data \n    training = pd.read_csv(\"/kaggle/input/dat1582/training_data.csv\")\n    # load data \n    test = pd.read_csv(\"/kaggle/input/dat1582/test_data.csv\")\n    all_data = pd.concat(map(pd.read_csv, [\"/kaggle/input/dat1582/training_data.csv\", \"/kaggle/input/dat1582/training_data.csv\"]))\n\n\n    train_data= training.sort_values(by=\"id\")\n    test_data = test.sort_values(by=\"id\")\n    all_data = all_data.sort_values(by=\"id\")\n    \n    return train_data, test_data, all_data\n\ntrain_data, test_data, all_data = data() ","metadata":{"execution":{"iopub.status.busy":"2023-09-26T09:52:19.643621Z","iopub.execute_input":"2023-09-26T09:52:19.644123Z","iopub.status.idle":"2023-09-26T09:52:20.742601Z","shell.execute_reply.started":"2023-09-26T09:52:19.644094Z","shell.execute_reply":"2023-09-26T09:52:20.741702Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"'''Transform data with pipeline'''\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n\ndef preprop(): \n    num_attribs = [\"rcount\",\"hematocrit\",\"neutrophils\",\"sodium\",\"glucose\",\n              \"bloodureanitro\",\"creatinine\",\"secondarydiagnosisnonicd9\",\n              \"respiration\",\"neutrophils\",\"bmi\",\"pulse\"]\n\n    cat_attribs = [\"facid\",\"dialysisrenalendstage\",\"asthma\",\n               \"irondef\",\"pneum\",\"substancedependence\",\n              \"psychologicaldisordermajor\",\"depress\",\n              \"psychother\",\"fibrosisandother\",\n              \"malnutrition\",\"hemo\",\"gender\"]\n\n    num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n\n\n    cat_pipeline = make_pipeline(\n        SimpleImputer(strategy=\"most_frequent\"),\n        OneHotEncoder(handle_unknown=\"ignore\"))\n\n    preprocessing = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", cat_pipeline, cat_attribs),\n    ])\npreprocessing = preprop() ","metadata":{"execution":{"iopub.status.busy":"2023-09-24T19:00:15.449299Z","iopub.execute_input":"2023-09-24T19:00:15.449727Z","iopub.status.idle":"2023-09-24T19:00:16.469425Z","shell.execute_reply.started":"2023-09-24T19:00:15.449691Z","shell.execute_reply":"2023-09-24T19:00:16.468188Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\"\"\"Linear regression - not a good performance\"\"\"\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nclass lin_reg(): \n    def lin_reg():\n        pass \n    def train(self,data):\n        preprocessing,labels,data = transform_data(data)\n        lin_reg = make_pipeline(preprocessing,LinearRegression())\n\n        print(\"training with length:\", len(data))\n        lin_reg.fit(data,labels)\n        return lin_reg \n    \n    def predict(self,data,lin_reg):\n        print(\"predict with length + \",len(data))\n        pred = lin_reg.predict(data)\n        return pred \n\n    #write to csv \n    def to_csv(self,data,pred): \n        preds = pred \n        ids = []\n        for index, row in data.iterrows():\n            for index, value in row.items():\n                if(index == \"id\"):\n                    ids.append(value)\n\n\n\n        df = pd.DataFrame({'id': ids,\n                           'lengthofstay': preds})\n        import os \n        if(not os.path.exists(\"./output\")):\n            os.makedirs(\"./output\")\n        df.to_csv(\"./output/linear_reg2.csv\",index=False)\n\n\n\n    def validate(self,data,lin_reg):\n        labels = data[\"lengthofstay\"].copy() \n        print(\"validate with length \", len(data))\n        pred = lin_reg.predict(data)\n        print(mean_squared_error(labels, pred,squared=False))\n        print(r2_score(labels, pred)) \n    \n\n    \n#my_lin_reg = lin_reg() \n\n#lin_reg = my_lin_reg.train(all_data)\n#my_lin_reg.validate(training,lin_reg)\n#pred = my_lin_reg.predict(test,lin_reg)\n#to_csv(test,pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Random Forest '''\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport matplotlib.pyplot as plt\nimport joblib \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n\nclass random_forrest: \n    def __init__(self,preprocessing):\n        self.model = None \n        self.preprocessing = preprocessing \n        \n    def load_model(self,path):\n        self.model = joblib.load(path)\n        \n        \n    def train(self,train_data): \n        training_data = train_data.drop(\"lengthofstay\",axis=1)\n        training_labels = train_data[\"lengthofstay\"].copy()\n\n        full_pipeline = Pipeline([\n            (\"preprocessing\", self.preprocessing),\n            (\"random_forest\", RandomForestRegressor(random_state=42)),\n        ])\n        #bisher 10 max features am besten \n        param_grid = [\n            {'random_forest__max_features': [16]            }\n\n        ]\n        self.model = GridSearchCV(full_pipeline, param_grid, cv=2,\n                                   scoring='neg_root_mean_squared_error',verbose=2)\n        self.model.fit(training_data, training_labels)\n    \n    \n\n    def measure(self,data):\n        print(\"measuring...\")\n        X = train_data.drop(\"lengthofstay\",axis=1)\n        y = train_data[\"lengthofstay\"].copy()\n        \n        pred = self.model.predict(X)\n        \n        print(\"mean squared: \" , mean_squared_error(y, pred,squared=False))\n        print(\"r2: \", r2_score(y, pred)) \n        self.compare(data,pred)\n        \n        \n    def compare(self,data,pred): \n        \"\"\"Look at the predictions compared to the labels\"\"\"\n        training_data = data.drop(\"lengthofstay\",axis=1)\n        labels = data[\"lengthofstay\"].copy()\n        x = data[\"id\"].copy() \n    \n        \n        x = x[2000:2100]\n        pred = pred[2000:2100]\n        labels = labels[2000:2100]\n        \n        plt.scatter(x, pred, color=\"red\",alpha=0.5)\n        plt.scatter(x,labels, color=\"blue\",alpha=0.5)\n        # Achsenbeschriftungen hinzufügen\n        plt.xlabel('X-Koordinaten')\n        plt.ylabel('Y-Koordinaten')\n\n        # Titel hinzufügen\n        plt.title('Streudiagramm')\n\n        # Diagramm anzeigen\n        plt.show()\n        \n    def to_csv(self,data,name=\"rf\"): \n        \n        pred = self.model.predict(data)\n        preds = []\n        \n        for e in pred:\n            preds.append(round(e))\n        ids = []\n        for index, row in data.iterrows():\n            for index, value in row.items():\n                if(index == \"id\"):\n                    ids.append(value)\n\n        \n\n        df = pd.DataFrame({'id': ids,\n                           'lengthofstay': preds})\n        import os \n        if(not os.path.exists(\"./output\")):\n            os.makedirs(\"./output\")\n        df.to_csv(\"./output/\"+name+\".csv\",index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-24T17:15:05.678261Z","iopub.execute_input":"2023-09-24T17:15:05.678696Z","iopub.status.idle":"2023-09-24T17:15:05.699098Z","shell.execute_reply.started":"2023-09-24T17:15:05.678662Z","shell.execute_reply":"2023-09-24T17:15:05.697922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best config: \n{'random_forest__max_depth': 36, 'random_forest__max_features': 16, 'random_forest__min_samples_leaf': 1} \nResult 5 folds:  \nmean squared:  0.24090335119740258  \nr2:  0.9895520308661191  \n\nResult 2 Folds:  \nmean squared:  0.24090335119740258  \nr2:  0.9895520308661191\n\nResult 10 Folds: \nmean squared:  0.24090335119740258\nr2:  0.9895520308661191\n","metadata":{}},{"cell_type":"code","source":"import joblib\nimport os \ndef train_and_save(): \n    rf = random_forrest(preprocessing) # 3 gride mit cv 2 = 0.24126; und 0.98952\n    rf.train(train_data)\n    rf.measure(train_data)\n    rf.to_csv(test,\"final grid\")\n\n    if(not os.path.exists(\"./models\")):\n        os.makedirs(\"./models\")\n    joblib.dump(rf.model, \"models/final.pkl\")","metadata":{"execution":{"iopub.status.busy":"2023-09-24T17:15:12.513106Z","iopub.execute_input":"2023-09-24T17:15:12.514531Z","iopub.status.idle":"2023-09-24T17:22:18.330930Z","shell.execute_reply.started":"2023-09-24T17:15:12.514441Z","shell.execute_reply":"2023-09-24T17:22:18.330137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def printModelInfo(): \n    cv_res = pd.DataFrame(rf.model.cv_results_)\n    cv_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n    print(cv_res)\n    print(rf.model.best_params_)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T17:04:47.697800Z","iopub.execute_input":"2023-09-24T17:04:47.699185Z","iopub.status.idle":"2023-09-24T17:04:47.724106Z","shell.execute_reply.started":"2023-09-24T17:04:47.699113Z","shell.execute_reply":"2023-09-24T17:04:47.722844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\nclass ensemble:\n    def __init__(self,prep):\n        self.pipeline = None \n        self.preprocessing = prep\n    def train(self,data):\n        print(\"training...\")\n        X = train_data.drop(\"lengthofstay\",axis=1)\n        y = train_data[\"lengthofstay\"].copy()\n        \n        voting_clf = VotingClassifier(\n                 estimators=[\n                 #('lr', LogisticRegression(random_state=42,max_iter=1000)),\n                 ('rf', RandomForestClassifier(random_state=42)),\n                 ('svc', SVC(random_state=42))\n                 ]\n        )\n        \n        self.pipeline = Pipeline([\n                ('prep', self.preprocessing),\n                ('voting_classifier', voting_clf)\n            ])\n        \n        self.pipeline.fit(X,y)\n    def measure(self,data):\n        print(\"measuring...\")\n        X = train_data.drop(\"lengthofstay\",axis=1)\n        y = train_data[\"lengthofstay\"].copy()\n        \n        pred = self.pipeline.predict(X)\n        \n        print(\"mean squared: \" , mean_squared_error(y, pred,squared=False))\n        print(\"r2: \", r2_score(y, pred)) \n        \n        \n        \n    def compare(self,data): \n        print(\"comparing....\")\n        \"\"\"Look at the predictions compared to the labels\"\"\"\n        training_data = data.drop(\"lengthofstay\",axis=1)\n        labels = data[\"lengthofstay\"].copy()\n        x = data[\"id\"].copy() \n        pred = self.pipeline.predict(training_data)\n        \n        \n        x = x[2000:2100]\n        pred = pred[2000:2100]\n        labels = labels[2000:2100]\n        \n        plt.scatter(x, pred, color=\"red\",alpha=0.5)\n        plt.scatter(x,labels, color=\"blue\",alpha=0.5)\n        # Achsenbeschriftungen hinzufügen\n        plt.xlabel('X-Koordinaten')\n        plt.ylabel('Y-Koordinaten')\n\n        # Titel hinzufügen\n        plt.title('Streudiagramm')\n\n        # Diagramm anzeigen\n        plt.show()\n        \n        \n    def to_csv(self,data,name=\"ensemble\"): \n        \n        pred = self.pipeline.predict(data)\n        preds = []\n        \n        for e in pred:\n            preds.append(round(e))\n        ids = []\n        for index, row in data.iterrows():\n            for index, value in row.items():\n                if(index == \"id\"):\n                    ids.append(value)\n\n        \n\n        df = pd.DataFrame({'id': ids,\n                           'lengthofstay': preds})\n        import os \n        if(not os.path.exists(\"./output\")):\n            os.makedirs(\"./output\")\n        df.to_csv(\"./output/\"+name+\".csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T11:12:26.220616Z","iopub.execute_input":"2023-09-24T11:12:26.221681Z","iopub.status.idle":"2023-09-24T11:12:26.412570Z","shell.execute_reply.started":"2023-09-24T11:12:26.221639Z","shell.execute_reply":"2023-09-24T11:12:26.411421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#e = ensemble(preprocessing)\n#e.train(train_data)\n#e.measure(train_data)\n#e.compare(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T11:12:32.371719Z","iopub.execute_input":"2023-09-24T11:12:32.372586Z","iopub.status.idle":"2023-09-24T11:31:30.924331Z","shell.execute_reply.started":"2023-09-24T11:12:32.372549Z","shell.execute_reply":"2023-09-24T11:31:30.921511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#install forever\n!pip install gradio --target=/kaggle/working/mysitepackages\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T09:56:15.795917Z","iopub.execute_input":"2023-09-26T09:56:15.796343Z","iopub.status.idle":"2023-09-26T09:57:05.227817Z","shell.execute_reply.started":"2023-09-26T09:56:15.796314Z","shell.execute_reply":"2023-09-26T09:57:05.226399Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-3.44.4-py3-none-any.whl (20.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\nCollecting altair<6.0,>=4.2.0 (from gradio)\n  Downloading altair-5.1.1-py3-none-any.whl (520 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.6/520.6 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fastapi (from gradio)\n  Downloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.5.1 (from gradio)\n  Downloading gradio_client-0.5.1-py3-none-any.whl (298 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx (from gradio)\n  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting importlib-resources<7.0,>=1.3 (from gradio)\n  Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\nCollecting jinja2<4.0 (from gradio)\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting markupsafe~=2.0 (from gradio)\n  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting matplotlib~=3.0 (from gradio)\n  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting numpy~=1.0 (from gradio)\n  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting orjson~=3.0 (from gradio)\n  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting packaging (from gradio)\n  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pandas<3.0,>=1.0 (from gradio)\n  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pillow<11.0,>=8.0 (from gradio)\n  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 (from gradio)\n  Downloading pydantic-2.4.0-py3-none-any.whl (395 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.4/395.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pydub (from gradio)\n  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\nCollecting python-multipart (from gradio)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyyaml<7.0,>=5.0 (from gradio)\n  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests~=2.0 (from gradio)\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nCollecting typing-extensions~=4.0 (from gradio)\n  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fsspec (from gradio-client==0.5.1->gradio)\n  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio)\n  Downloading jsonschema-4.19.1-py3-none-any.whl (83 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting toolz (from altair<6.0,>=4.2.0->gradio)\n  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting filelock (from huggingface-hub>=0.14.0->gradio)\n  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\nCollecting tqdm>=4.42.1 (from huggingface-hub>=0.14.0->gradio)\n  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\nCollecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n  Downloading fonttools-4.42.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib~=3.0->gradio)\n  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-dateutil>=2.7 (from matplotlib~=3.0->gradio)\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tzdata>=2022.1 (from pandas<3.0,>=1.0->gradio)\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\nCollecting pydantic-core==2.10.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio)\n  Downloading pydantic_core-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests~=2.0->gradio)\n  Downloading charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (201 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting idna<4,>=2.5 (from requests~=2.0->gradio)\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests~=2.0->gradio)\n  Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting certifi>=2017.4.17 (from requests~=2.0->gradio)\n  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting click>=7.0 (from uvicorn>=0.14.0->gradio)\n  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting anyio<4.0.0,>=3.7.1 (from fastapi->gradio)\n  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sniffio (from httpx->gradio)\n  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\nCollecting exceptiongroup (from anyio<4.0.0,>=3.7.1->fastapi->gradio)\n  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\nCollecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\nCollecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n  Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\nCollecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n  Downloading rpds_py-0.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.7->matplotlib~=3.0->gradio)\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=232fea8999c169b3a8de8aa34c26a8d70a736d27866b00dc0122d7904bfda074\n  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\nSuccessfully built ffmpy\nInstalling collected packages: pytz, pydub, ffmpy, websockets, urllib3, tzdata, typing-extensions, tqdm, toolz, sniffio, six, semantic-version, rpds-py, pyyaml, python-multipart, pyparsing, pillow, packaging, orjson, numpy, markupsafe, kiwisolver, importlib-resources, idna, h11, fsspec, fonttools, filelock, exceptiongroup, cycler, click, charset-normalizer, certifi, attrs, annotated-types, aiofiles, uvicorn, requests, referencing, python-dateutil, pydantic-core, jinja2, contourpy, anyio, starlette, pydantic, pandas, matplotlib, jsonschema-specifications, huggingface-hub, httpcore, jsonschema, httpx, fastapi, gradio-client, altair, gradio\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.0 which is incompatible.\nbeatrix-jupyterlab 2023.621.222118 requires jupyter-server~=1.16, but you have jupyter-server 2.6.0 which is incompatible.\nbotocore 1.31.17 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.5 which is incompatible.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 6.7.0 which is incompatible.\ncmudict 1.0.13 requires importlib-resources<6.0.0,>=5.10.1, but you have importlib-resources 6.1.0 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.9.2 which is incompatible.\ngoogle-auth 2.20.0 requires urllib3<2.0, but you have urllib3 2.0.5 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.1 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.0.1 requires urllib3<2.0.0, but you have urllib3 2.0.5 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.26.0 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\ns3fs 2023.9.0 requires fsspec==2023.9.0, but you have fsspec 2023.9.2 which is incompatible.\ntensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.26.0 which is incompatible.\nwoodwork 0.26.0 requires numpy<1.25.0,>=1.22.0, but you have numpy 1.26.0 which is incompatible.\nydata-profiling 4.3.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.0 which is incompatible.\nydata-profiling 4.3.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.1.1 which is incompatible.\nydata-profiling 4.3.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.4.0 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\nypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 23.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.1.1 annotated-types-0.5.0 anyio-3.7.1 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.7 contourpy-1.1.1 cycler-0.11.0 exceptiongroup-1.1.3 fastapi-0.103.1 ffmpy-0.3.1 filelock-3.12.4 fonttools-4.42.1 fsspec-2023.9.2 gradio-3.44.4 gradio-client-0.5.1 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 idna-3.4 importlib-resources-6.1.0 jinja2-3.1.2 jsonschema-4.19.1 jsonschema-specifications-2023.7.1 kiwisolver-1.4.5 markupsafe-2.1.3 matplotlib-3.8.0 numpy-1.26.0 orjson-3.9.7 packaging-23.1 pandas-2.1.1 pillow-10.0.1 pydantic-2.4.0 pydantic-core-2.10.0 pydub-0.25.1 pyparsing-3.1.1 python-dateutil-2.8.2 python-multipart-0.0.6 pytz-2023.3.post1 pyyaml-6.0.1 referencing-0.30.2 requests-2.31.0 rpds-py-0.10.3 semantic-version-2.10.0 six-1.16.0 sniffio-1.3.0 starlette-0.27.0 toolz-0.12.0 tqdm-4.66.1 typing-extensions-4.8.0 tzdata-2023.3 urllib3-2.0.5 uvicorn-0.23.2 websockets-11.0.3\n\u001b[33mWARNING: Target directory /kaggle/working/mysitepackages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#load model and install gradio \ndef load_model(): \n    import joblib\n    return joblib.load(\"/kaggle/input/final-random-forrest/final.pkl\")\nmodel = load_model()\n\n#%pip install gradio > /dev/null\n# add to system path\nimport sys\nsys.path.append('/kaggle/working/mysitepackages')\n\nimport gradio as gr ","metadata":{"execution":{"iopub.status.busy":"2023-09-26T09:57:29.657141Z","iopub.execute_input":"2023-09-26T09:57:29.657797Z","iopub.status.idle":"2023-09-26T09:57:30.010814Z","shell.execute_reply.started":"2023-09-26T09:57:29.657766Z","shell.execute_reply":"2023-09-26T09:57:30.009636Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":" \n\nimport pandas as pd\ntrain_data = pd.read_csv(\"/kaggle/input/dat1582/training_data.csv\")\ndef predict(bmi,sex,asthma,iron,creat):\n    \n\n\n\n    \n    standard_data = train_data.iloc[[0]]\n    standard_data.iat[0,standard_data.columns.get_loc(\"bmi\")] = bmi\n    standard_data.iat[0,standard_data.columns.get_loc(\"gender\")] = \"M\"\n    standard_data.iat[0,standard_data.columns.get_loc(\"asthma\")] = asthma\n    standard_data.iat[0,standard_data.columns.get_loc(\"irondef\")] = iron\n    standard_data.iat[0,standard_data.columns.get_loc(\"creatinine\")] = creat\n    \n    pred = model.predict(standard_data)\n    ergebnis = int(float(pred[0]))\n\n    return ergebnis\n  \n\n\n\npredict(22.5,\"M\",False,False,0.5)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T09:57:36.386722Z","iopub.execute_input":"2023-09-26T09:57:36.387657Z","iopub.status.idle":"2023-09-26T09:57:36.849706Z","shell.execute_reply.started":"2023-09-26T09:57:36.387618Z","shell.execute_reply":"2023-09-26T09:57:36.848728Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{}}]},{"cell_type":"code","source":"# doesnt work in kaggle but works in spaces: https://huggingface.co/spaces/JonasFeierabend/DAT158\n\n\n# Set the minimum, maximum, and default values for the sliders\n\nbmi_min, bmi_max, bmi_default = 15, 50, 25\n\n\n# Create the interface\niface = gr.Interface(\n    fn=predict, \n    inputs=[\n        gr.components.Slider(minimum=bmi_min, maximum=bmi_max, value=bmi_default, label=\"BMI\"),\n        gr.components.Dropdown(choices=[\"M\", \"F\"],label=\"Geschlecht\",value=\"M\"),\n        gr.components.Checkbox(label=\"Asthma\"),\n        gr.components.Checkbox(label=\"Irondefizit\"),\n        gr.components.Slider(minimum=0.1, maximum=2.5, value = 0.5, label=\"Creatine\")\n    ], \n    outputs=gr.components.Textbox(label=\"Prediction\"),\n    title=\"Diabetes Predictor\",\n    description=\"\"\"Enter your age, BMI, and glucose level to predict whether you are diabetic or non-diabetic.\n    Data source: Pima Indians Diabetes Database; Model: Random Forest Classifier\"\"\",\n)\n\n# Launch the interface\niface.launch(share=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T09:57:40.033689Z","iopub.execute_input":"2023-09-26T09:57:40.034666Z","iopub.status.idle":"2023-09-26T09:57:44.497513Z","shell.execute_reply.started":"2023-09-26T09:57:40.034608Z","shell.execute_reply":"2023-09-26T09:57:44.496757Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://6945474e46d8079325.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://6945474e46d8079325.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]}]}